# Machine Learning Notes 04


## 5. 神经网络 neural networks

### 5.1 神经元模型

神经元neuron是神经网络最基本的成分。

M-P神经元模型模仿生物神经网络，通过激活函数activation function处理神经元输出。

* 激活函数是阶跃函数，其输入值被映射成0或1，其中，1对应神经元兴奋，0对应神经元抑制。
* 但是由于阶跃函数的不连续性，实际常使用 Sigmoid函数作为激活函数，它可以将值挤压到(0,1)之间，有时也被叫做挤压函数squashing function。

将许多的神经元按照一定层次结构连接起来，就得到神经网络。

### 5.2 感知机perceptron与多层网络

perceptron由两层神经网络组成，输入层接受外界输入信号后传递给输出层，输出层是M-P神经元也叫做阈值逻辑单元 threshold logic unit。感知机能容易地实现逻辑与、或、非运算。

感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，学习能力十分有限。因此，对于非线性问题就要考虑多层功能神经元，两层感知机就能解决异或问题。

常见的神经网络是每层的每个神经元都会与下一层神经元全互连，不存在同层连接和跨层连接，这被称为 多层前馈神经网络 multi-layer feedforward neural networks。

* 输入层接受外界输入信号，不进行函数处理
* 隐层与输出层对包含功能神经元，会对信号加工处理
* 输出层进行输出

可知，只要有隐层，就是对层网络。

### 5.3 误差逆传播算法 Error BackPropagation

误差逆传播是最成功地训练多层网络的算法。不仅可用于多层前馈神经网络，还可用于其他类型神经网络，比如递归神经网络。但通常来说BP网络就是多层前馈神经网络。

假设，多层神经网络是拥有d个输入神经元、l个输出神经元、q个隐层神经元的多层前馈网络结构。输入信号x和输入层与隐层之间的连接权相乘得到，即，隐层到输出的输入信号。隐层与输出层之间的连接权乘以该输入信号的到输出层的输入信号，最后将信号输出得到y。

BP神经网络由于强大的表示能力会经常遭遇股过拟合。一般两种策略来缓解：

1. 早停early stopping
2. 正则化 regularization

